---
title: "DCDM Project Log"
author: "Alicia"
editor: visual
format: html
---

# TRE Egress

Ella - is there anything to write here?

# Data Cleaning

```{r}
rm(list = ls())

# Install and load Tidyverse packages
#install.packages(c("tidyverse", "janitor", "stringr"))
library(tidyverse)
library(janitor)
library(stringr)
```

```{r}
# Define the working directory path in r
# Alicia
rootDir = "/Users/aliciahobdell/Desktop/data_cleaning/DCDM_group3/"
# Sanj 
#rootDir = "/Users/sanjanasrinivasan/Desktop/DCDM_IMPC_Project/"
# Ella
#rootDir = ""
# Sama
#rootDir = ""
# Esta
#rootDir = ""
```

## Cleaning the Raw Data Files

### Combining the Raw Data in a Table (Esta?)

--\> This step can be done in bash after quality control (collating by Ella).

The dataset comprises thousands of CSV files. The key fields include: analysis_id, pvalue, parameter_name, gene_symbol, mouse_strain, parameter_id, gene_accession_id, mouse_life_stage.

To ensure efficient quality checks and facilitate further analysis, it is essential to combine all these files into a single, unified table based on their common fields.

Here’s a function that reads data from a file and transforms it into a row for a larger table:

```{r}
# Function to read a file and transform its contents into a single row
read_and_transform <- function(file) {
  
  # Read the file
  data <- read.csv(file, header = FALSE, col.names = c("field", "value"))
  # - header = FALSE: Tells R to treat the first row as regular data, not column names.
  # - col.names = c("field", "value"): Assigns consistent column names to facilitate clear and reliable subsetting in subsequent processing.

  # Convert all field names to lowercase for uniformity
  data$field <- tolower(data$field)
  
  # Transpose the 'value' column so that fields become column names
  transformed_data <- t(data$value) %>% 
    as.data.frame() %>% 
    setNames(data$field)
  
  # Rearrange columns to place 'analysis_id' as the first column
  transformed_data <- transformed_data %>%
    relocate(analysis_id, .before = everything())

  # Return the transformed data as a single-row data frame
  return(transformed_data)
}
```

The function can now be applied to all CSV files in the `raw_data` directory to combine them into a single table using the `map_dfr()` function from the **`purrr`** package.

```{r}
# List all CSV files in the raw_data directory
all_files <- list.files(paste0(rootDir, "data/raw_data"), pattern = "\\.csv$", full.names = TRUE)

# Apply the read_and_transform function to each file and combine results into a single data frame
analysis_table <- purrr::map_dfr(all_files, read_and_transform)
# Display the first 6 rows of the data table
head(analysis_table)

# Specify the path to the cleaned directory
output_path <- paste0(rootDir, "data/cleaned/analysis_table.txt")

# Save the combined table to a new txt file
write.table(analysis_table, file = output_path, sep = ",", quote = FALSE, row.names = FALSE)
```

### Quality Control/Cleaning Using the SOP (Esta)

The experiment data comes with an SOP specifying constraints for each field, including data type, minimum and maximum values for numerical data, length for strings, and specific values for certain fields. Data quality can be assessed by comparing the raw data to these predefined constraints.

First, have a look at the SOP to identify the constraints.

```{r}
SOP <- read.csv(paste0(rootDir, "data/metadata/IMPC_sop.csv"))
SOP
```

For each column, we need to check similar things, like whether the data is the correct type (e.g., string or number), whether it has the right length (for strings) or size (for floats), and whether it matches allowed values, like for `mouse_strain` and `mouse_life_stage`. We may also need to find missing values. For each issue, we want to print the value and its index. To make this process less repetitive, we can create reusable functions.

*Here, it would be good to check if the functions work as intended on values that should output an error (e.g. fake table containing rows each violating a single constraint for a parameter).*

```{r}
# These functions check if values meet specific criteria and return the indices of values that do not meet the criteria.

# Function to validate values based on the SOP type ("String" or "Float")
# For strings, it checks the string length; for numeric values, it checks the value directly.
validate_type_minmax <- function(x, dataType, min_val, max_val) {
  if (tolower(dataType) == "string") {
    which(sapply(x, nchar) < min_val | sapply(x, nchar) > max_val)
  } else if (tolower(dataType) == "float") {
    which(as.numeric(x) < min_val | as.numeric(x) > max_val)
  } 
}

# Check if values in a list are within the allowed values of a given vector
check_allowed_values <- function(values, allowed_values) {
  which(!values %in% allowed_values) # Find indices of invalid values
}

# Function to combine multiple lists of indices and return unique indices
combine_unique_indices <- function(...) {
  sort(unique(unlist(list(...))))
}

# Function to print the indices and values were issues were identified
print_invalid_indices_and_values <- function(x, variable_name, invalid_indices) {
  # Count the number of issues
  num_issues <- length(invalid_indices)
  
  # Print the contextual message
  cat("The '", variable_name, "' column has ", num_issues, " issue(s).\n", sep = "")
  
  # Print indices and values if there are any issues
  if (num_issues > 0) {
    cat("Indices:\n")
    print(invalid_indices)
    cat("Values:\n")
    print(x[invalid_indices])
  }
}
```

Now that we have defined these functions, we can loop through the data table fields, extract the corresponding constraints from the SOP, and validate them using the functions.

```{r}
# Extract field names from the data table
field_names <- colnames(analysis_table)
print(field_names)
  
# Loop through each field name
for (field_name in field_names) {
    cat("Processing field:", field_name, "\n")
    
    # Extract the corresponding row in the SOP
    sop_row <- SOP[SOP$dataField == field_name, ]
    
    # Access the column by name
    column <- analysis_table[[field_name]]
    
    # Validate the column based on SOP constraints
    SOP_constraints <- validate_type_minmax(column, sop_row$dataType, sop_row$minValue, sop_row$maxValue)
    
  # Check field-specific constraints
  # Initialize a variable for checking valid values
  field_specific_check <- integer(0) # Default to an empty vector

  if (field_name == "mouse_strain") {
    valid_mouse_strains <- c("C57BL", "B6J", "C3H", "129SV")
    field_specific_check <- check_allowed_values(column, valid_mouse_strains)
  } else if (field_name == "mouse_life_stage") {
    valid_mouse_life_stages <- c(
      "E12.5", "E15.5", "E18.5", "E9.5", 
      "Early adult", "Late adult", "Middle aged adult"
    )
    field_specific_check <- check_allowed_values(column, valid_mouse_life_stages)
  } else if (field_name == "analysis_id") {
    # Check if unique
    field_specific_check <- which(duplicated(column))
  } else if (field_name == "gene_symbol") {
    # Check if in title format
    field_specific_check <- which(!grepl("^[A-Z][a-zA-Z0-9]*$", column))
  }
    
    # Combine all indices of invalid values
    indices <- combine_unique_indices(SOP_constraints, field_specific_check)
    
    # Print the invalid indices and their corresponding values
    print_invalid_indices_and_values(column, field_name, indices)
}
```

*The next step is to handle the issues. Do we cap the p-values at 1? Do we remove the data from incorrect strains?*

## Cleaning the Metadata Files

### `IMPC_procedure.txt (Alicia)`

Each row includes: 1) a line number 2) a name 3) a description 4) a boolean indicating if the procedure is mandatory 5) the original IMPC ID.

**Issues**:

-   Unnecessary double quotes surrounding columns –\> Remove unnecessary quotes and fix column separators.

-   Commas in the description column misinterpreted as separators –\>Enclose the description column in double quotes.

-   `line_number` and `procedureId` duplicate the same unique information –\> Replace `line_number` with `procedureId`.

-   HTML symbols appear incorrectly encoded but will be ignored for simplicity –\> Clean file encoding and ignore invalid characters.

```{bash}
# Define working directory path in bash
rootDir="/Users/aliciahobdell/Desktop/data_cleaning/DCDM_group3/"

# Clean the IMPC_procedure.txt file
sed 's/^"//;s/"$//;s/" "/,/g' "${rootDir}/data/metadata/IMPC_procedure.txt" | 
sed -E 's/^([0-9]+,[^,]+,)(.*)(, (TRUE|FALSE), [0-9]{5})$/\1"\2"\3/' |
sed -E 's/^line_number,//' |
iconv -f UTF-8 -t UTF-8//IGNORE > "${rootDir}/data/cleaned/cleaned_IMPC_procedure.txt"

# Completion message
echo "IMPC_procedure.txt successfully cleaned and saved."

# perl -MHTML::Entities -pe 'decode_entities($_);'> "${rootDir}/data/cleaned/cleaned_IMPC_procedure.txt"
```

```{r}
# Load the cleaned procedure data, setting procedureId as row names
procedure <- read.table(
  file = paste0(rootDir, "data/cleaned/cleaned_IMPC_procedure.txt"),
  header = TRUE,                
  sep = ",",                    
  quote = '"',                  
)

# Display the first few rows of the data
head(procedure)

# Find the maximum string length in the 'name' column
max(nchar(procedure$name))
# Find the maximum string length in the 'description' column
max(nchar(procedure$description))
# Count the number of duplicated values in the 'impcParameterOrigId' column
sum(duplicated(procedure$impcParameterOrigId))
# Count the number of missing (NA) values in the 'isMandatory' column
sum(is.na(procedure$isMandatory))
```

Since the file loads correctly in R, we can confirm that the regular expression (REGEX) accurately matched the columns when enclosing the description. This ensures that each column is in the correct format, so there is no need to further check the column formatting. Additionally, the **procedureId** and **impcParameterOrigId** columns don't contain duplicated values.

### `IMPC_parameter_description.txt (Sama)`

```{bash}
#| eval: false

# Define working directory path in bash
rootDir="/Users/aliciahobdell/Desktop/data_cleaning/DCDM_group3/"
sed -E 's/^"//; s/"$//; s/" "/,/g;' "${rootDir}/data/metadata/IMPC_parameter_description.txt" |
sed -E 's/^([0-9]{1,4},[0-9]{5}, )(.*)(,[^,]+, IMPC_[A-Z]{3}_[0-9]{3}_[0-9]{3})$/\1"\2"\3/' |
sed -E 's/^x//' > "${rootDir}/data/cleaned/cleaned_IMPC_parameter_description.txt"
```

```{r}
#| eval: false

# Load the cleaned parameter data
parameter_description <- read.table(
  file = paste0(rootDir, "data/cleaned/cleaned_IMPC_parameter_description.txt"), # File path
  header = TRUE,                 # First row contains column names
  sep = ",",                     # Fields are separated by commas
  stringsAsFactors = FALSE,      # Prevent character columns from converting to factors
  check.names = FALSE            # Keep column names as-is, even if they contain spaces or special characters
)

# Display the loaded data in a tabular format
head(parameter_description)
```

### `disease_information.txt (Sanj)`

The Disease_information.txt file contains metadata with four key columns: disease_id, disease_term, gene_accession_id, and phenodigm_score.

Issues:

-   Unecessary rows and formatting (redundant "x" row at the top, row numbers and surrounding double quotes embedded within data) –\> Remove unnecessary rows, row numbers and extraneous quotes

-   The disease_term column contains commas misinterpreted as separators -\> Combine split fields to ensure disease_term remains intact

-   phenodigm_score contains non-numeric characters and extra spaces -\> Clean non-numeric values and safely convert to numeric format

-   Row numbers and quotes appear in the disease_id column -\> Clean disease_id to remove row numbers and quotes

-   Duplicate disease_id values exist –\> We need to decide if they are meaningful (they have unique phenodigm scores for reference)

Let's review what the data looks like.

```{r}

# Load raw file
raw_lines <- readLines(paste0(rootDir, "data/metadata/Disease_information.txt"))

# Inspect the first few rows
head(raw_lines, 13)
```

Key Observations: 1)An unnecessary x row exists at the top. 2) Row numbers and extra quotes are embedded in the data. disease_term fields contain commas causing extra splits.

To prepare the data for further processing:1) Remove the first "x" row. 2) Strip row numbers and surrounding quotes.

```{r}
# Remove the "x" row
cleaned_lines <- raw_lines[-1]  # Remove the first row ("x")

# Remove row numbers and surrounding quotes
cleaned_lines <- cleaned_lines %>%
  str_remove_all('^\\d+\\"\\s') %>%   #
  str_remove_all('^"|"$')           # Remove the outer pair of quotes


# Inspect the cleaned lines
head(cleaned_lines, 14)
```

Some disease_term fields contain commas, splitting the data into extra columns. Here, we fix that issue by combining split fields.

```{r}
# Function to process and clean split rows
process_split_row <- function(row) {
  # Split the row by commas outside quotes
  split_row <- str_split(row, ",\\s*(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)")[[1]]
  
  # Check if the split_row has more than 4 fields (indicating a split disease term)
  if (length(split_row) > 4) {
    # Combine extra fields in the disease_term column
    disease_term <- paste(split_row[2:(length(split_row) - 2)], collapse = ", ")
    return(c(split_row[1], disease_term, split_row[length(split_row) - 1], split_row[length(split_row)]))
  } else {
    # Return the row as is if it's already properly split
    return(split_row)
  }
}

# Apply the function to all cleaned lines
split_data <- map(cleaned_lines, process_split_row)

#Inspect split_data
str(split_data) #This revealed that the phenodigm scores are character values

# Inspect a sample of split_data
head(split_data, 20)

# Find problematic rows (e.g., empty or improperly split rows)
problematic_rows <- which(map_int(split_data, length) != 4)
print("Indices of problematic rows:")
print(problematic_rows) #Shows that all the rows have been split well

# Create data_frame from split_data 
data_frame <- split_data %>%
  map(~ set_names(as.list(.), c("disease_id", "disease_term", "gene_accession_id", "phenodigm_score"))) %>%
  bind_rows()

```

The phenodigm_score column contains non-numeric characters and spaces. We clean and convert it safely to numeric.

```{r}

# Clean the phenodigm_score column
data_frame <- data_frame %>%
  mutate(
    phenodigm_score = str_trim(phenodigm_score),  # Remove leading/trailing spaces
    phenodigm_score = str_replace_all(phenodigm_score, "[^0-9\\.]", "")  # Remove non-numeric characters except "."
  )

#After cleaning, convert the column to numeric.
data_frame <- data_frame %>%
  mutate(
    phenodigm_score = as.numeric(phenodigm_score)
  )

#After cleaning, check for any remaining NAs
remaining_na <- data_frame %>%
  filter(is.na(phenodigm_score))

print("Rows with remaining NA values in phenodigm_score:")
print(remaining_na)

#Inspect the data to verify changes
str(data_frame)
summary(data_frame)
```

Final Cleanup: Fix Rows and Disease IDs 1) Drop the extra header row. 2) Clean disease_id to remove row numbers and quotes.

```{r}
# Remove the first row
data_frame <- data_frame[-1, ]  # Drop the first row
head(data_frame)

# Clean disease_id column
data_frame <- data_frame %>%
  mutate(
    disease_id = str_remove(disease_id, '^\\d+\\"\\s'), # Remove row numbers and quotes
    disease_id = str_remove_all(disease_id, '^"|"$')    # Remove any remaining outer quotes
  )

#Verify changes
head(data_frame)

```

Final Quality Checks: Verify the dataset for: correct data types, missing values, duplicates, proper formatting

```{r}
# Verify data types
str(data_frame)

# Confirm numeric values for phenodigm_score
summary(data_frame$phenodigm_score)

# Count missing values in each column
colSums(is.na(data_frame)) #shows there are no missing values in any of the columns

# Verify uniqueness of disease_id
unique_disease_ids <- nrow(data_frame) == length(unique(data_frame$disease_id))

if (unique_disease_ids) {
  print("All disease_id values are unique!")
} else {
  print("Warning: Duplicate disease_id values found.")
} #Duplicate disease_id values found!!!

# Check disease_id format (e.g., OMIM:xxxx or ORPHA:xxxx)
invalid_disease_ids <- data_frame %>%
  filter(!str_detect(disease_id, "^(OMIM|ORPHA):\\d+$"))

print("Invalid disease_id values:")
print(invalid_disease_ids) #none

# Check gene_accession_id format (e.g., MGI:xxxxx)
invalid_gene_ids <- data_frame %>%
  filter(!str_detect(gene_accession_id, "^MGI:\\d+$"))

print("Invalid gene_accession_id values:")
print(invalid_gene_ids) #none

```

Are duplicate disease_ids meaningful? Should we leave them as is or should we aggregate them into unique rows by taking a mean of the phenodigm score?

Saving and Loading the Final Data

```{r}

# Specify the path to the cleaned directory
output_path <- paste0(rootDir, "data/cleaned/cleaned_Disease_information.txt")

# Save data_frame as a tab-delimited text file
write.table(data_frame, file = output_path, sep = "\t", row.names = FALSE, quote = FALSE)

# Load the final cleaned data
disease_information <- read.table(
  file = output_path, 
  header = TRUE,          # Use the first row as column names 
  sep = "\t",             # Tab-delimited
  stringsAsFactors = FALSE) # Avoid character columns from converting to factors

# Verify the loaded data
str(disease_information)

#Display the cleaned and loaded data in tabular format
head(disease_information)

```

# Collating (Ella)

# MySQL Database

```{sql}
#| eval: false

-- Check if MySQL is running
ps -ef | grep mysql

-- Connect to MySQL
mysql -u root -p --local-infile=1
-- local-infile=1 enables data import from local files using LOAD DATA LOCAL INFILE.
```

## Create Database and Schemas

```{sql}
#| eval: false

-- Create the database
CREATE DATABASE IMPCDb;

-- Select the database
USE IMPCDb;
```

```{sql}
#| eval: false

-- Create tables without foreign keys first

-- Table: Gene
CREATE TABLE Genes (
    gene_id VARCHAR(11) PRIMARY KEY,           -- SOP: 9 to 11 alphanumeric characters
    gene_symbol VARCHAR(13)                    -- SOP: 1 to 13 alphanumeric characters
) COMMENT = 'Stores gene identifiers and symbols. Referenced by Analyses and PhenodigmScores (one-to-many).';


-- Table: ProcedureTable (Procedure is a reserved keyword in SQL)
CREATE TABLE Procedures (
    procedure_id INT PRIMARY KEY,              -- Unique identifier for each procedure (impcParameterOrigId)
    procedure_name VARCHAR(47),                -- Max length: 47 characters
    procedure_description VARCHAR(1090),       -- Max length: 1090 characters
    procedure_isMandatory BOOLEAN NOT NULL     -- No missing values; TRUE/FALSE
        DEFAULT FALSE
) COMMENT = 'Stores procedure details (name, description, mandatory). Linked to Parameters via a many-to-many join.';


-- Table: Disease
CREATE TABLE Diseases (
    disease_id VARCHAR(50) PRIMARY KEY,        -- Unique identifier for each disease
    disease_term VARCHAR(150)                  -- Descriptive term for the disease
) COMMENT = 'Stores disease identifiers and terms. Linked to Genes in PhenodigmScores (many-to-many).';


-- Table: ParameterGroupings
CREATE TABLE ParameterGroupings (
    grouping_id INT PRIMARY KEY AUTO_INCREMENT,   -- Automatically increments for each new row
    grouping_name VARCHAR(50)                     -- Name of the parameter group
) COMMENT = 'Defines groups of parameters. Linked to Parameters via a many-to-many join.';


-- Table: Parameter
CREATE TABLE Parameters (
    parameter_id VARCHAR(18) PRIMARY KEY,          -- SOP: 15 to 18 characters
    parameter_name VARCHAR(74),                    -- SOP: 2 to 74 characters
    parameter_description VARCHAR(1000)            -- Descriptive field for the parameter
) COMMENT = 'Stores parameter metadata. Linked to Procedures and ParameterGroupings (many-to-many) and referenced by Analyses (one-to-many).';

-- Create tables with foreign keys

-- Table: Analysis
CREATE TABLE Analyses (
    analysis_id VARCHAR(15) PRIMARY KEY,           -- SOP: 15 alphanumeric character string
    gene_id VARCHAR(11),                           -- SOP: 9 to 11 alphanumeric characters
    mouse_life_stage VARCHAR(17),                  -- SOP: 4 to 17 characters
    mouse_strain VARCHAR(5),                       -- SOP: 3 to 5 alphanumeric characters
    parameter_id VARCHAR(18),                      -- Foreign key to Parameter table
    p_value FLOAT,                                 -- SOP: Float from 0 to 1
    FOREIGN KEY (gene_id) REFERENCES Genes(gene_id),
    FOREIGN KEY (parameter_id) REFERENCES Parameters(parameter_id)
) COMMENT = 'Stores analysis results linking Genes and Parameters (many-to-one), including p-values and strain info.';


-- Table: GeneDisease
CREATE TABLE PhenodigmScores (
    phenodigm_id INT AUTO_INCREMENT PRIMARY KEY,

    disease_id VARCHAR(50),                        -- Foreign key to Disease table
    gene_id VARCHAR(11),                           -- Foreign key to Gene table
    phenodigm_score FLOAT,                         -- Phenodigm association score
    FOREIGN KEY (disease_id) REFERENCES Diseases(disease_id),
    FOREIGN KEY (gene_id) REFERENCES Genes(gene_id)
) COMMENT = 'Stores gene-disease association scores (many-to-many) linking Genes and Diseases.';


-- Create join tables

-- Table: ParameterProcedure
CREATE TABLE parameterXprocedure (
    parameter_id VARCHAR(18),                      -- Foreign key to Parameter table
    procedure_id INT,                              -- Foreign key to ProcedureTable
    PRIMARY KEY (parameter_id, procedure_id),      -- Composite primary key to ensure uniqueness
    FOREIGN KEY (parameter_id) REFERENCES Parameters(parameter_id),
    FOREIGN KEY (procedure_id) REFERENCES Procedures(procedure_id)
) COMMENT = 'Join table linking Parameters to Procedures (many-to-many).';


-- Table: ParameterGroup
CREATE TABLE parameterXgroup (
    grouping_id INT,                               -- Foreign key to ParameterGroupings table
    parameter_id VARCHAR(18),                      -- Foreign key to Parameter table
    PRIMARY KEY (grouping_id, parameter_id),       -- Composite primary key to ensure uniqueness
    FOREIGN KEY (grouping_id) REFERENCES ParameterGroupings(grouping_id),
    FOREIGN KEY (parameter_id) REFERENCES Parameters(parameter_id)
) COMMENT = 'Join table linking Parameters to ParameterGroupings (many-to-many).';
```

## Populate Database

To populate the database, the schema should first be examined to identify which attributes correspond to each table. Data should then be organized into separate CSV or TSV files, with each file representing a single table. Each file is expected to include a header row (optional but recommended) that matches the column names defined in the database schema.

Once a CSV file has been created for each table, the data can be loaded directly into MySQL using the `LOAD DATA INFILE` command.

-   **`FIELDS TERMINATED BY ','`**: Indicates that fields are separated by commas.

-   **`OPTIONALLY ENCLOSED BY '"'`**: Handles strings enclosed in double quotes.

-   **`IGNORE 1 LINES`**: Skips the header row in the CSV, if present.

### Procedure Table

```{r}
# Load procedure table 
procedure <- read_delim(paste0(rootDir, "data/cleaned/cleaned_IMPC_procedure.txt"), delim = ",", quote = "\"")

# Subset, rename columns, and select unique rows
procedures <- procedure %>%
  clean_names() %>% 
  select(impc_parameter_orig_id, name, description, is_mandatory) %>%  # Select specific columns
  distinct() %>%                                                   # Keep only unique rows
  rename(procedure_id = impc_parameter_orig_id,                       # Rename columns
         procedure_name = name,
         procedure_description = description,
         procedure_isMandatory = is_mandatory)

head(procedures)
# Save the table as CSV 
write.csv(procedures, file = paste0(rootDir, "/data/collated/Procedures.csv"), row.names = FALSE, quote = TRUE)
```

```{sql}
#| eval: false
-- Path to tables 
LOAD DATA LOCAL INFILE '/Users/aliciahobdell/Desktop/data_cleaning/DCDM_group3/data/cleaned/Procedures.csv'
INTO TABLE Procedures
FIELDS TERMINATED BY ',' 
OPTIONALLY ENCLOSED BY '"'
IGNORE 1 LINES;
```

### Genes Table

```{r}
# Load analysis table 
analysis <- read_delim(paste0(rootDir, "data/cleaned/analysis_table.txt"), delim = ",")
disease <- read_delim(paste0(rootDir, "data/cleaned/cleaned_Disease_information.txt"), delim = "\t")
head(disease)

# Subset the table, ensure unique rows, convert gene symbols to title case, and rename
genes <- analysis %>%
  clean_names() %>% 
  mutate(gene_symbol = str_to_title(gene_symbol)) %>%  # Convert gene_symbol to title case 
  select(gene_accession_id, gene_symbol) %>%          # Select specific columns
  distinct() %>%                                      # Keep only unique rows
  rename(gene_id = gene_accession_id)                 # Rename columns

# Find `gene_id`s in `disease` table that are not in `genes`
missing_genes <- disease %>%
  select(gene_accession_id) %>%                # Extract gene IDs from `disease`
  rename(gene_id = gene_accession_id) %>%
  distinct() %>%                               # Ensure unique rows
  filter(!gene_id %in% genes$gene_id)          # Find those not in `genes`

# Add missing `gene_id`s to `genes` with `gene_symbol` as NULL; here we could manually search them and add them! 
genes <- genes %>%
  bind_rows(missing_genes %>% 
  mutate(gene_symbol = NA)) %>% # Add missing genes with NA for gene_symbol
  distinct()                    # Ensure no duplicates

head(genes)

# Save the table as CSV 
write.csv(genes, file = paste0(rootDir, "/data/collated/Genes.csv"), row.names = FALSE)
```

```{sql}
#| eval: false
LOAD DATA LOCAL INFILE '/Users/aliciahobdell/Desktop/data_cleaning/DCDM_group3/data/collated/Genes.csv'
INTO TABLE Genes
FIELDS TERMINATED BY ',' 
OPTIONALLY ENCLOSED BY '"'
IGNORE 1 LINES;
```

### Parameters Table

```{r}
# Load analysis table 
parameter <- read_delim(paste0(rootDir, "data/cleaned/cleaned_IMPC_parameter_description.txt"), delim = ",")


# Select the subset of columns required for the Parameters table
parameters <- parameter %>%
  clean_names() %>% 
  mutate_all(~ str_trim(.)) %>%                       # Trim leading/trailing whitespace
  mutate_all(~ ifelse(. %in% c("", "NA"), NA, .)) %>% # Replace empty strings or "NA" with actual NA
  select(parameter_id, name, description) %>%          # Select only the specific columns needed
  rename(parameter_id = parameter_id,                  # Rename the columns
         parameter_name = name,                      
         parameter_description = description) %>%
  group_by(parameter_id) %>%                          # Group by parameter_id
  slice_min(nchar(parameter_name), with_ties = FALSE) %>% # Keep the row with the shortest parameter_name
  ungroup()                                     # Remove grouping

parameters[(nchar(parameters$parameter_name))> 74, ]
# Save the table as CSV 
write.csv(parameters, file = paste0(rootDir, "/data/collated/Parameters.csv"), row.names = FALSE, quote = TRUE)
```

*\*Some of the IDs appeared to be duplicated, but upon inspection, the rows contained equivalent values (e.g., for IMPC_HIS_010_001: "Eye with optic nerve - Severity score" and "Eye - Severity score"). Given the same identifier and the similarity of these terms, it is reasonable to assume that they refer to the same parameter, and only one of the duplicates was uploaded to the database.*

![](images/Screenshot%202024-12-18%20at%2015.27.00.png)

*Some values are truncated, which aligns with the SOP specifying a maximum of 74 characters. However, the maximum number of characters in the dataset is 88, exceeding the allowed limit.*

![](images/Screenshot%202024-12-18%20at%2015.26.12.png)

```{sql}
#| eval: false
LOAD DATA LOCAL INFILE '/Users/aliciahobdell/Desktop/data_cleaning/DCDM_group3/data/collated/Parameters.csv'
INTO TABLE Parameters
FIELDS TERMINATED BY ',' 
OPTIONALLY ENCLOSED BY '"'
IGNORE 1 LINES;
```

### Disease Table

```{r}
# Select the subset of columns required for the Parameters table
diseases <- disease %>%
  clean_names() %>% 
  select(disease_id, disease_term) %>%          # Select only the specific columns needed
  distinct()

head(diseases)

write.csv(diseases, file = paste0(rootDir, "/data/collated/Diseases.csv"), row.names = FALSE, quote = TRUE) 
```

```{sql}
#| eval: false
LOAD DATA LOCAL INFILE '/Users/aliciahobdell/Desktop/data_cleaning/DCDM_group3/data/collated/Diseases.csv'
INTO TABLE Diseases
FIELDS TERMINATED BY ',' 
OPTIONALLY ENCLOSED BY '"'
IGNORE 1 LINES;
```

### PhenoDigm Score Table

```{r}
# Select the subset of columns required for the Parameters table
phenodigm_scores <- disease %>%
  clean_names() %>% 
  select(disease_id, gene_accession_id, phenodigm_score) %>%          # Select only the specific columns needed
  distinct()

write.csv(phenodigm_scores, file = paste0(rootDir, "/data/collated/PhenodigmScores.csv"), row.names = FALSE, quote = TRUE) 
```

```{sql}
#| eval: false
LOAD DATA LOCAL INFILE '/Users/aliciahobdell/Desktop/data_cleaning/DCDM_group3/data/collated/PhenodigmScores.csv'
INTO TABLE PhenodigmScores
FIELDS TERMINATED BY ',' 
OPTIONALLY ENCLOSED BY '"' 
LINES TERMINATED BY '\n' 
IGNORE 1 LINES
(disease_id, gene_id, phenodigm_score); -- so that the phenodigm_id is created dynamically
```

## parameterXprocedure

```{r}
parameterXprocedure <- parameter %>%
  clean_names() %>% 
  mutate_all(~ str_trim(.)) %>%                       # Trim leading/trailing whitespace
  mutate_all(~ ifelse(. %in% c("", "NA"), NA, .)) %>% # Replace empty strings or "NA" with actual NA
  select(parameter_id, impc_parameter_orig_id)   %>%   
  rename(# Select only the specific columns needed  rename(parameter_id = parameter_id,                  # Rename the columns
      parameter_id = parameter_id,                      
      procedure_id = impc_parameter_orig_id) %>%
    distinct()


head(parameterXprocedure)
# Save the table as CSV 
write.csv(parameterXprocedure, file = paste0(rootDir, "/data/collated/parameterXprocedure.csv"), row.names = FALSE, quote = TRUE)
```

```{sql}
#| eval: false
LOAD DATA LOCAL INFILE '/Users/aliciahobdell/Desktop/data_cleaning/DCDM_group3/data/collated/parameterXprocedure.csv'
INTO TABLE parameterXprocedure
FIELDS TERMINATED BY ',' 
OPTIONALLY ENCLOSED BY '"' 
LINES TERMINATED BY '\n'
IGNORE 1 LINES; -- so that the phenodigm_id is created dynamically
```

### Analysis Table

```{r}
# Load analysis table 
analysis <- read_delim(paste0(rootDir, "data/cleaned/analysis_table.txt"), delim = ",")

head(analysis)
analyses <- analysis %>%
  clean_names() %>% 
  mutate_all(~ str_trim(.)) %>%                       # Trim leading/trailing whitespace
  mutate_all(~ ifelse(. %in% c("", "NA"), NA, .)) %>% # Replace empty strings or "NA" with actual NA
  select(analysis_id, gene_accession_id, mouse_strain, mouse_life_stage, parameter_id, pvalue)   %>%  
    rename(# Select only the specific columns needed  rename(parameter_id = parameter_id,                  # Rename the columns
      p_value = pvalue)   %>%  
    distinct()
head(analyses)
write.csv(analyses, file = paste0(rootDir, "/data/collated/Analyses.csv"), row.names = FALSE, quote = TRUE)
```

```{sql}
#| eval: false
LOAD DATA LOCAL INFILE '/Users/aliciahobdell/Desktop/data_cleaning/DCDM_group3/data/collated/Analyses.csv'
INTO TABLE Analyses
FIELDS TERMINATED BY ',' 
OPTIONALLY ENCLOSED BY '"' 
LINES TERMINATED BY '\n'
IGNORE 1 LINES; -- so that the phenodigm_id is created dynamically
```

## Determining Groupings

To reduce the parameter space the  collaborator would like to start grouping parameters together based on phenotype test similarity and/or naming similarity. Design the database to reflect new groupings for weight,  images and brain parameters, plus at least 3 others of your choice (refer to below). 

In addition to the data provided, each group must  find at least 3 other parameter groupings from the parameter list and add this to the  database. We encourage you to find as many additional parameter groups as you can and  time permits, however only 3 more is compulsory. parameters

```{r}
parameters <- parameters %>%
  mutate(
    parameter_group = case_when(
      str_detect(parameter_name, regex(
        "weight|density|fat|lean|BMI|BMC|mass|composition|bone|length|adipose|lipid|body size|size|growth|skeletal|area|volume", 
        ignore_case = TRUE)) ~ "Weight",
      str_detect(parameter_name, regex(
        "image|screenshot|microscope|pdf|lacz|waveform|ogram|resolution|visual|pixel|scan|photo|imaging|bit depth|microscopy|contrast", 
        ignore_case = TRUE)) ~ "Images",
      str_detect(parameter_name, regex(
        "brain|cortex|hippo|thalamus|amygdala|lobe|cere|spinal|pituitary|striatum|hypothal|neural|neuronal|pons|medulla|ganglion|nerve|enceph|ventricle|choroid", 
        ignore_case = TRUE)) ~ "Brain",
      str_detect(parameter_name, regex(
        "heart|cardiac|vascular|blood|vein|aort|arter|HR|stroke|ejection|QT|circulation|pulse|pressure|rate|systolic|diastolic|respiration|ECG|cardio|valve", 
        ignore_case = TRUE)) ~ "Cardiovascular"
      )
)

parameters %>%
  group_by(parameter_group) %>%
  summarise(total_parameters = n()) %>%
  arrange(desc(total_parameters))

parameters$parameter_name[is.na(parameters$parameter_group)]

```

# R/Shiny

**Test R/Shiny 1:** They want the ability to select a particular knockout mouse and visualise the statistical scores of all phenotypes tested.

```{sql}
#| eval: false
SELECT Analyses.p_value, Parameters.parameter_name 
FROM Analyses 
JOIN Parameters ON Analyses.parameter_id = Parameters.parameter_id 
WHERE Analyses.gene_id IN (
    SELECT gene_id 
    FROM Genes 
    WHERE gene_symbol IN ('Ifi204', 'Mettl21c', 'Ier5', 'Abca4')
)
ORDER BY Analyses.p_value ASC;
```

![](images/Screenshot 2024-12-21 at 16.21.52.png)

**Test R/Shiny 2:** The collaborator also wishes to visualise the statistical scores of all knockout mice for a selected phenotype.

```{sql}
#| eval: false
SELECT Analyses.p_value, Genes.gene_symbol 
FROM Analyses 
JOIN Parameters ON Analyses.parameter_id = Parameters.parameter_id 
JOIN Genes ON Analyses.gene_id = Genes.gene_id 
WHERE Parameters.parameter_name IN (
    'Facial Cleft',
    'Lens Opacity',
    'Triglycerides',
    'Skin color - tail',
    'Potassium',
    'HRV',
    'Hindbrain morphology',
    'Aspartate aminotransferase',
    'Tibia length',
    'Left total retinal thickness',
    'Embryo Size',
    'Effector CD4+ T helper cells - % of live leukocytes (Panel A)',
    'Limb morphology',
    'Coat - color - back',
    'Aggression',
    'Joints'
)
ORDER BY Analyses.p_value ASC;
```

![](images/Screenshot 2024-12-21 at 16.22.09.png)

**Test R/Shiny 3:** The collaborator would like to visualise clusters of genes with similar phenotype scores.  

```{sql}
#| eval: false

SELECT Genes.gene_symbol, Parameters.parameter_name, Analyses.p_value FROM Analyses JOIN Parameters ON Analyses.parameter_id = Parameters.parameter_id JOIN Genes ON Analyses.gene_id = Genes.gene_id; 
```

![](images/Screenshot 2024-12-21 at 16.22.33.png)
